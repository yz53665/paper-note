# 1. 计算图
计算图使用节点表示变量，边表示操作。
![[Pasted image 20240320195112.png](../attach/Pasted%20image%2020240320195112.png)

# 2. 链式求导法则
![[Pasted image 20240320195203.png](../attach/Pasted%20image%2020240320195203.png)
根据链式求导法则，有：
$$
\frac{dz}{dx}=\frac{dz}{dy}\cdot \frac{dy}{dx}
$$
![[Pasted image 20240320195330.png](../attach/Pasted%20image%2020240320195330.png)
同理可得：
$$
\frac{dz}{dx}=\frac{dz}{dx}\cdot \frac{dx}{ds} + \frac{dz}{dy}\cdot \frac{dy}{ds}
$$

而对于较为复杂的公式也可以通过图直观表达出来：
![[Pasted image 20240320200045.png](../attach/Pasted%20image%2020240320200045.png)
求导时只需从顶端向下求导即可：
![[Pasted image 20240320200119.png](../attach/Pasted%20image%2020240320200119.png)

更加复杂的例子：
![[Pasted image 20240320200230.png](../attach/Pasted%20image%2020240320200230.png)
![[Pasted image 20240320200256.png](../attach/Pasted%20image%2020240320200256.png)
![[Pasted image 20240320200323.png](../attach/Pasted%20image%2020240320200323.png)
![[Pasted image 20240320200400.png](../attach/Pasted%20image%2020240320200400.png)
注意这里的x要看作3个不同的x

# 3. 深度学习中的梯度计算
RNN的计算
![[Pasted image 20240320201158.png](../attach/Pasted%20image%2020240320201158.png)
![[Pasted image 20240320201203.png](../attach/Pasted%20image%2020240320201203.png)

![[Pasted image 20240320201209.png](../attach/Pasted%20image%2020240320201209.png)
![[Pasted image 20240320201252.png](../attach/Pasted%20image%2020240320201252.png)
所以如果要计算关于h_0的梯度，需要连乘迭代次数，时间复杂度是O(n^t)