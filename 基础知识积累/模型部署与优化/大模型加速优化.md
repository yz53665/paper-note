### vllm
+ 采用PagedAttention，将原本由于KV-cache而导致的内存浪费通过分块存储的方式进行改善
+ 使用memory sharing，将单个prompt产出的多个不同序列映射到同一个物理块实现共享
+ 无需加载模型，只需要用一个类加载对应的模型文件即可使用，并且支持直接启动在线服务