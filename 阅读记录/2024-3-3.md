---
Title: Deconstructing Denoising Diffusion Models for Self-Supervised Learning
Year: "2024"
Publisher: Arxiv
tags:
  - waypoints
  - goal
  - refine
  - GMM
  - GCN
Datasets:
  - ETH-UCY
  - SDD
输入:
  - position
输出:
  - position
  - disaplacement
多模态:
  - distribution
概率建模:
  - GMM
基于意图: true
关系提取:
  - GCN
关系衡量:
  - relative position
  - disaplacement
解决问题:
  - 累积误差
  - 未来关系
预测结构: 
未来环境建模: 用于训练阶段反向训练基于RNN的VAE分布
---

低维隐空间表达是的DAE（Denoising Autoencoder）获得良好特征表达能力的关键。
DDM（Denoising Diffusion Model）的表达能力是来自于降噪过程，而不是扩散过程。

##### DDM背景：
扩散过程：
$$
z_t = \gamma_tz_0 + \sigma_t \epsilon, \  \epsilon \sim \mathcal{N}(0, I)
$$
$$
\gamma_t^2 + \sigma_t^2 = 1
$$
DAE是学习干净的输出，DDM是学习$\epsilon$，其损失函数：
$$
\parallel \epsilon - net(z_t)\parallel^2
$$
在生成过程则是反复调用模型减去噪音，直到获得干净的信号$z_0$。

具体使用时：
+ 直接将原始图片作为$z_0$
+ 在tokenizer生成的隐空间上应用DDM（Sora），这种时候都需要一个预训练的tokenizer用于映射（一般是autoencoder）

