### 主要难点
##### 1. 表征 Representation
如何利用多模态的互补性和冗余性的方式表示和总结多模态数据。
相比起单模态直接将数据不断压缩提取，多模态需要考虑互相之间的互补性，剔除冗余性从而学习更好的特征表示

###### 1.1 联合表征 Joint Representation
将多模态数据统一映射到一个多模态向量空间。
主要关注互补性：
![[Pasted image 20240414225823.png](attach/Pasted%20image%2020240414225823.png)
###### 1.2 协同表征 Coordinated Representation
将每个模态映射到各自的表示空间，但互相之间满足一定的相关性约束
主要关注数据间相关性
通常网络目标是优化协作关系（如相似性）
CLIP、ALIG的对比学习就是这种关系

##### 2. 翻译Translation

##### 3. 对齐 Alignment
从多种不同模态之间识别元素之间的直接关系。例如食谱步骤与制作的菜肴视频对齐
需要测良不同模式之间的相似度并处理可能的长期依赖和歧义
###### 3.1 显式对齐
如果主要任务是对齐，那么可以分类为显示对齐。重要方法是相似性度量，包含：
+ 无监督对齐：没有标注，需要同时学习相似度度量和对齐方式
+ 有监督：有对齐标注，主要学习相似性度量

###### 3.2 隐式对齐
只是任务的中间步骤，在训练期间潜在对齐

###### 4. 融合 Fusion
来自不同模态的信息可能具有不同的预测能力和噪声拓扑，并且可能在至少一种模态中丢失数据
###### 4.1 模型无关方法
+ 早期融合：模型浅层时将多个模态拼接起来，再级联深度网络结构。**缺点**：多个模态数据来源不一致，拼接难度大，对数据预处理敏感
+ 晚期融合（late fusion）：独立训练多个模型，在预测时再融合。**缺点**：没有充分利用模态间底层特征相关性，计算复杂度大
+ 混合融合（hybird Fusion）：同时结合两者，以及在模型中间层进行特征交互，一种逐级融合方式。在不同层级上对不同模态融合。

###### 4.2 基于模型的方法
+ 深度学习网络
+ 多核学习
+ 图形模型

### 应用背景
+ 目标检测
+ 语义分割
+ Tracking

## 分类
#### 大致分类
+ 早期融合
+ 特征融合
+ 后融合

#### 两大类四小类
+ 强融合
+ 弱融合

+ 早期融合
+ 深度（特征）融合
+ 后期融合
+ 不对称融合（两个分支特征进行相互决策）

![[Pasted image 20240411205100.png](attach/Pasted%20image%2020240411205100.png)

## 融合模式

#### Early-Fusion
![[Pasted image 20240411205214.png](attach/Pasted%20image%2020240411205214.png)
具体包括：
+ 转换后concat
+ 特征信息融合
+ 特征语义连接后成为输入

#### Deep-fusion
![[Pasted image 20240411205523.png](attach/Pasted%20image%2020240411205523.png)
对提取后的高维度特征图通过一系列下游模块进行融合

#### Late-fusion
![[Pasted image 20240411210021.png](attach/Pasted%20image%2020240411210021.png)
后融合（目标对象级别融合）
可以看作是利用多模态信息对最终方案进行优化的集成方法

#### Asymmetry-fusion
![[Pasted image 20240411210330.png](attach/Pasted%20image%2020240411210330.png)
两个分支处于不同的阶段，并且一个分支占据主导低位，另一个分支提供辅助信息完成最后的任务

例如：卷积网络可以滤掉没有实际语义信息的无意义店，融合时避免噪点干扰。

#### Weak-Fusion
![[Pasted image 20240411210729.png](attach/Pasted%20image%2020240411210729.png)
不直接从多模态分支融合，而是通常基于规则的方法，利用一种模式中的数据作为监督信息，指导另一种模式的交互。如上图在处理中两个分支不会发生主干直接交互，而是通过弱连接的方式（如loss函数）进行信息融合。


## 当前主流

##### Align(light  fusion)
+ fusion方式通常简单，如向量内积
+ 如CLIP和ALIGN
+ 是双塔结构
+ 重点在对齐

##### Fuse(heavy fusion)
+ 基于Transformer
+ 有VLP、OSCAR、UNITER、VINVL
+ 单塔结构
+ 利用attention机制融合
+ 可以实现VQA、caption等需要信息融合和理解的下游任务（Align不行）
+ 效率弱于CLIP