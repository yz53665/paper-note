What matters when building vision-language models?

+ 好的主干语言模型对性能影响显著，且影响大于视觉模型
+ 但模态预训练冻结时，交叉注意力优于自回归；解冻时自回归优于交叉
+ 完全自回归可能训练不稳，采用LoRA可以稳定并提升性能
+ 在数据足够前提下，多token可以提升性能
+ 可训练池化（如Perceiver）可以降低token数并提升性能
+ 直接将图像分块而不固定宽高比影响不大，但可以节省GPU
+ 训练时图像切割为子图联合原图输入，在推理时可以灵活处理