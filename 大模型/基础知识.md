## 大模型开发路径
#### 1. 从头构建
+ 投入大，性能突出
![[Pasted image 20240408214436.png](attach/Pasted%20image%2020240408214436.png)
##### 训练基座模型
+ 已有认知基础，但需要复杂指令准确引导
+ GPT基座均基于Transformer的decoder思路
+ 实现涌现能力的基础
+ ChatGPT用到近万张A100训练
+ 相当于小学生死记硬背大量古诗，可以对上下句，但无法理解含义，如背诵思乡诗

##### 策略精调
+ 让基座模型理解用户想问什么，自己回答是否正确
+ 需要高质量人工标注\<指令，答案\>来优化模型（prompt工程）

##### 训练独立于基座模型的判别模型
+ 判断生成结果质量，为下一步强化学习准备
+ 由标注人员对结果按照相关性、富含信息性、有害信息进行排序，然后用判别模型学习标注好的排名数据，形成对结果的判断能力。

##### 强化学习
+ 利用奖励机制根据上一阶段打分结果来更新内容生成模型参数

#### 2. 基于开源通用大模型调优
+ 成本低，使用1张高性能显卡5小时就能完成含有200万条数据的参数微调
+ 在保持原有大模型整体参数或者绝大部分参数不变的情况下，增加或改变参数来获得更好的输出
+ 经典的如微软LoRA技术

## 评测方法

#### 1. 深度学习常用语言理解数据集和评价指标
+ 准确率、召回率
+ Meta、谷歌和华盛顿大学合作退出SuperGLUE（超级通用语言理解评估）包含7个任务集合
适合初步评估基本性能
#### 2. 通过提问（Prompt）方式进行评价

##### 人工评测
由领域专家主观判断
适合评估高层语言表达能力、情感理解能力和交互性能
##### 裁判大模型评测
用更加强大的模型来评测
适合快速评测，评估稳定性和一致性


## 灾难性遗忘
学习了新知识后，几乎彻底遗忘之前的内容，使得模型无法增量式学习和不断适应新环境（ChatGPT如何接入网络？）



