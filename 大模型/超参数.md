## Warmup
+ 初始以较小的学习率训练，然后再修改为预设学习率
+ 过程：warmup增长率为1/warmup_steps，然后线性增长，在指定步数达到完整学习率
+ 原因
	+ 初始梯度方向可能与期望方向相反
	+ 初始权重为随机初始化，较大的学习率可能导致不稳定，通过小学习率warmup，可以使得模型趋于稳定再开始正式学习，有助于加快模型收敛速度

## LoRA
#### LoRA alpha

+ 低秩近似