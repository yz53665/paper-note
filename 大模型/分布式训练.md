
## 1. 数据并行（Data Parallel）
将每个batch切分放入不同GPU 中训练更新参数

## 2. 流水线并行（Pipeline Parallel）
将模型前后切分：
![[Pasted image 20240822100243.png](../img/Pasted%20image%2020240822100243.png)

存在问题：
1. GPU利用率不够
![[Pasted image 20240822100308.png](../img/Pasted%20image%2020240822100308.png)
2. 中间结果占用大量内存

解决方案：
1. 在原有的batch数据基础上，再划分成若干个batch称为micro-batch，像流水线一样进行计算
![[Pasted image 20240822112030.png](image/Pasted%20image%2020240822112030.png)
2. 几乎不存储中间结果，反向传播时再重新计算

## 3. 张量并行
在层内进行分割，即将运算分配到不同的GPU上面
![[Pasted image 20240822114230.png](image/Pasted%20image%2020240822114230.png)
优点：张量并行存储效率高
缺点：每次前向和后向会引入额外通信开销


# Deepspeed Zero

可存储模型状态：模型参数（2A）、模型梯度（2A）、Adam状态（3X4A）

### zero1
Adam进行分片

### zero2
Adam+梯度分片

### zero3
Adam+梯度+参数分片

### zero offload
显存不足，内存来补，时间换空间，在zero2基础上将adam状态和梯度转移到cpu内存，会很慢

