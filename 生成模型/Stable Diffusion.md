### 文生图

+ 使用CLIP Text Encoder 模型将输入文本信息编码，输出特征矩阵
+ 再用random函数生成高斯噪声矩阵，作为latent Feature结合文本特征输入SD模型
+ 将优化迭代后的Latent Feature输入图像解码器中（VAE Decoder），重建为像素图
![[Pasted image 20240415230407.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415230407.png)

### 图生图

![[Pasted image 20240415230426.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415230426.png)

中间的图像优化模块由U-Net和一个Schedule算法共同组成
+ U-Net负责预测噪声，不断优化生成过程，在预测噪声的同时不断注入文本语义信息
+ schedule算法对每次的U-Net预测的噪声进行优化处理（动态调整预测的噪声，控制U-Net预测的噪声强度），统筹生成的进度
+ SD中U-Net的迭代优化步数50~100次，在该过程中Latent Feature质量不断变好（纯噪声减少，语义信息增加，文本语义信息增加

![[Pasted image 20240415230749.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415230749.png)

## 核心原理

+ SD基于扩散模型
+ 过程分步化可迭代
+ 具备较强泛化能力，核心是前向扩散和反向迭代
![[Pasted image 20240415231538.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415231538.png)

+ 基于Latent的扩散模型，可以大大降低显存占用和计算复杂度

## 训练过程

将图片加入随机噪声，就可以看作一个sample。通过该数据集，可以训练一个噪声预测器，可以对添加噪声的图像去噪，也可以预测添加的噪声

前向过程（加噪）：训练噪声预测器
反向过程（去噪）：生成图像

text embedding通过cross-attn与U-Net融合
![[Pasted image 20240415232818.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415232818.png)

## 核心网络结构

+ 提示词输入，文本编码
+ 潜在空间压缩：VAE将高维度图像压缩至低维度潜在空间
+ 正向扩散：潜在空间中逐步添加噪声扩散图像，最终转化为完全随机的噪声分布。使得图像特征逐步消失
+ 噪声预测器：模型学习预测添加的噪声。一个U-Net网络学习如何从噪声中恢复出原始图像
+ 反向扩散：用噪声预测器估计潜在图像噪声，迭代去除噪声，恢复出清晰的图像
+ 条件生成：通过提示词引导图像生成。
+ VAE解码：通过VAE解码转换回原始的像素空间

![[Pasted image 20240415233442.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415233442.png)

VAE结构
![[Pasted image 20240415233751.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415233751.png)
## 训练时损失函数
+ L1回归损失：预测值与真实值差异
+ 感知损失：比较原始图像与生成图像在传统深度学习模型（VGG、ResNet、ViT）中不同层中的特征图的相似度，而不是像素级别的对比
+ PatchGAN判别器损失：对VAE进行对抗训练，提升生成图像的局部真实性与清晰度
+ KL正则化：调整latent特征使其零中心化并保持最小方差（标准正态分布）

## CLIP模型
![[Pasted image 20240415234151.png](../%E5%A4%A7%E6%A8%A1%E5%9E%8B/attach/Pasted%20image%2020240415234151.png)
